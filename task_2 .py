# -*- coding: utf-8 -*-
"""Task 2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xOePSjJvEgAOVfHh5PAzEd8DX-64zQKR

#Lab assignment no:1 Task 2

Classification algoritham for The Street View House Numbers (SVHN) Dataset

### *Submitted by : Athulya Ganapathi kandy
###*SJSU ID:013773994

###Loading of  Required libraries
"""

import keras
import tensorflow as tf
from keras.datasets import mnist
from __future__ import absolute_import, division, print_function
import numpy as np
import seaborn as sns
from scipy.io import loadmat
from skimage import color
from skimage import io
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

tf.logging.set_verbosity(tf.logging.INFO)

"""##Preprocessing of image dataset

###Loading of dataset from the website
"""

!wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat
 
!wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat

"""###Reading the .MAT files"""

def load_data(path):
    """ Helper function for loading a MAT-File"""
    data = loadmat(path)
    return data['X'], data['y']
  

train_data, train_labels = load_data('train_32x32.mat')
eval_data, eval_labels = load_data('test_32x32.mat')

print("Training Set", train_data.shape, train_labels.shape)
print("Test Set", eval_data.shape, eval_labels.shape)

"""###Loading of keras functions"""

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.optimizers import Adam
from keras.callbacks import TensorBoard

"""####Transposing the the train and test data by converting it from  (width, height, channels, size) -> (size, width, height, channels)"""

# Transpose the image arrays
train_data,train_labels = train_data.transpose((3,0,1,2)), train_labels[:,0]
eval_data, eval_labels = eval_data.transpose((3,0,1,2)), eval_labels[:,0]

print("Training Set", train_data.shape)
print("Test Set", eval_data.shape)

"""###Plotting Function for fig in n rows X m columns"""

def plot_images(img, labels, nrows, ncols):
    """ Plot nrows x ncols images
    """
    fig, axes = plt.subplots(nrows, ncols)
    for i, ax in enumerate(axes.flat): 
        if img[i].shape == (32, 32, 3):
            ax.imshow(img[i])
        else:
            ax.imshow(img[i,:,:,0])
        ax.set_xticks([]); ax.set_yticks([])
        ax.set_title(labels[i])

"""####Plot some of the training images"""

plot_images(train_data, train_labels, 3, 9)

"""####Plot some of testing set images"""

plot_images(eval_data, eval_labels, 3, 9)

"""####Converting Label 10 -> 0"""

train_labels[train_labels == 10] = 0
eval_labels[eval_labels == 10] = 0

"""####Printing of unique values"""

print(np.unique(train_labels))

"""**Grayscale Conversion**:
To speed up our experiments we will convert our images from RGB to Grayscale, which grately reduces the amount of data we will have to process.

Y = 0.2990R + 0.5870G + 0.1140B
"""

def rgb2gray(images):
    return np.expand_dims(np.dot(images, [0.2990, 0.5870, 0.1140]), axis=3)

train_greyscale = rgb2gray(train_data).astype(np.float32)
test_greyscale = rgb2gray(eval_data).astype(np.float32)
print("Training Set", train_greyscale.shape)
print("Test Set", test_greyscale.shape)
print('')

plot_images(train_greyscale, train_labels, 3, 9)

"""###Reshaping the data"""

train_greyscale =train_greyscale.reshape(-1, 32, 32, 1)

test_greyscale = test_greyscale.reshape(-1, 32, 32, 1)
InputShape = (32, 32, 1)

train_greyscale = train_greyscale.astype('float32')
test_greyscale = test_greyscale.astype('float32')

train_greyscale /= 255
test_greyscale /= 255

print('train_greyscale shape:', train_greyscale.shape)

print('test_greyscale shape:', test_greyscale.shape)

"""###Treatment of predictor labels as categorical variables"""

num_category = 10

train_labels = keras.utils.to_categorical(train_labels, num_category)
eval_labels = keras.utils.to_categorical(eval_labels, num_category)

"""##Convolution neural network"""

MyModel = Sequential()

"""###First layer in convolution with 'relu' as activation function"""

MyModel.add(Conv2D(100, kernel_size=(7, 7), activation='relu', input_shape=InputShape))

"""###Second layer in convolution with 'relu' as activation function"""

MyModel.add(Conv2D(10, (4, 4), activation='relu'))

"""###Maxpooling for dimention reduction"""

MyModel.add(MaxPooling2D(pool_size=(2, 2)))

MyModel.add(Dropout(0.25))

MyModel.add(Flatten())

"""###Dense layer in convultion"""

MyModel.add(Dense(128, activation='relu'))

MyModel.add(Dropout(0.5))

"""###Logits Layer"""

MyModel.add(Dense(num_category, activation='softmax'))

MyModel.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])

num_epoch = 5

"""###Calculation of loss and accuracy checking of the model"""

model_log = MyModel.fit(train_greyscale, train_labels, batch_size=100, epochs=num_epoch, verbose=1, validation_data=(test_greyscale, eval_labels))

"""##Error analysis"""

rounded_predictions = MyModel.predict_classes(test_greyscale, batch_size=10, verbose=False)

# %matplotlib inline
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import itertools

"""###Creation of confusion matrix"""

cm = confusion_matrix(np.argmax(eval_labels, axis = 1), rounded_predictions)

def plot_confusion_matrix(cm, classes,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
   
    print(cm)
    plt.figure(figsize=(12, 8))

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

cm_plot_labels = [str(i) for i in range(10)]
cm_plot_labels

"""###Confusion matrix"""

plot_confusion_matrix(cm, cm_plot_labels, title = "Confusion Matrix")

"""###Confusion Matrix as Percentages"""

# Set the figure size
plt.figure(figsize=(12, 8))

# Normalize the confusion matrix
cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100.0

# Visualize the confusion matrix
sns.heatmap(cm, annot=True, cmap='Reds', fmt='.1f', square=True);

"""###Vizualization of Loss of Training vs. Test over Epochs"""

# summarize history for accuracy
plt.plot(model_log.history['acc'])
plt.plot(model_log.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""### Vizualization of Loss of Training vs. Test over Epochs"""

plt.plot(model_log.history['loss'])
plt.plot(model_log.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()